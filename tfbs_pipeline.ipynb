{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the package you are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Input, Dropout, LSTM, Activation, Bidirectional, GRU\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dna2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dna2vec.multi_k_model import MultiKModel\n",
    "\n",
    "filepath = 'dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'\n",
    "mk_model = MultiKModel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "968      1\n",
       "240      1\n",
       "819      1\n",
       "692      1\n",
       "420      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(['label', 'id'], axis=1)\n",
    "X_train.head()\n",
    "X_train = X_train.values\n",
    "\n",
    "y_train = train_data[['label']]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "1860      0\n",
       "353       1\n",
       "1333      0\n",
       "905       1\n",
       "1289      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data.drop(['label', 'id'], axis=1)\n",
    "X_test.head()\n",
    "X_test = X_test.values\n",
    "\n",
    "y_test = test_data[['label']]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sequences to kmers representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCGGG', 'GGGGC', 'GGCGA', 'CGAGC', 'AGCCT', 'CCTC']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getKmers(sequence, k=5, stride=2):\n",
    "    return [sequence[x:x+k] for x in range(0,len(sequence) - k + stride,2)]\n",
    "\n",
    "getKmers(\"GCGGGGCGAGCCTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "stride = 2\n",
    "L = len(X_train[0,0])\n",
    "N = int(np.ceil((L - k) / stride + 1))\n",
    "vec_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequences2Vec(X):            \n",
    "    m = X.shape[0]\n",
    "    X_vec = np.zeros((m, N, vec_dim))\n",
    "    for i in range(m):\n",
    "        words = getKmers(X[i,0])\n",
    "        j = 0\n",
    "        for word in words:\n",
    "            vec = mk_model.vector(word)        \n",
    "            X_vec[i][j] = vec\n",
    "            j+=1            \n",
    "    return X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class SequencesToVecs(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Convert sequences to vecs \"\"\"\n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)       \n",
    "    def fit(self, texts, y=None):        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        m = X.shape[0]\n",
    "        X_vec = np.zeros((m, N, vec_dim))\n",
    "        for i in range(m):\n",
    "            words = getKmers(X[i,0])\n",
    "            j = 0\n",
    "            for word in words:\n",
    "                vec = mk_model.vector(word)        \n",
    "                X_vec[i][j] = vec\n",
    "                j+=1            \n",
    "        return X_vec\n",
    "        \n",
    "sequencer = SequencesToVecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec_train = Sequences2Vec(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat a RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfbs_LSTM(input_shape=[6,100]):\n",
    "    # create the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbs_lstm = KerasClassifier(tfbs_LSTM, epochs=40, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sequencestovecs', SequencesToVecs()), ('kerasclassifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4db434ef98>)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions on test set...\n",
      "Test accuracy: 87.00 %\n"
     ]
    }
   ],
   "source": [
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfbs_LSTM_Dropout(input_shape=[6,100]):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfbs_lstm_dropout = KerasClassifier(tfbs_LSTM_Dropout, epochs=40, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sequencestovecs', SequencesToVecs()), ('kerasclassifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4d95f515c0>)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_lstm_dropout)\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions on test set...\n",
      "Test accuracy: 87.25 %\n"
     ]
    }
   ],
   "source": [
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8726593164829121"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfbs_BiLSTM(input_shape=[6,100]):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))    \n",
    "    model.add(Dense(1))    \n",
    "    model.add(Activation('sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbs_bilstm = KerasClassifier(tfbs_BiLSTM, epochs=40, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sequencestovecs', SequencesToVecs()), ('kerasclassifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4d569d8748>)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_bilstm)\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions on test set...\n",
      "Test accuracy: 87.50 %\n"
     ]
    }
   ],
   "source": [
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfbs_BiGRU(input_shape=[6,100]):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape))\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(Dropout(0.5))    \n",
    "    model.add(Dense(1))    \n",
    "    model.add(Activation('sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbs_bigru = KerasClassifier(tfbs_BiGRU, epochs=40, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sequencestovecs', SequencesToVecs()), ('kerasclassifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4d569d8470>)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_bigru)\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions on test set...\n",
      "Test accuracy: 88.25 %\n"
     ]
    }
   ],
   "source": [
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 0.3901 - acc: 0.8312\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.3079 - acc: 0.8725\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.2923 - acc: 0.8819\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.2665 - acc: 0.8975\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.2600 - acc: 0.9019\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.2415 - acc: 0.9038\n",
      "Epoch 7/20\n",
      "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2376 - acc: 0.9044\n",
      "Epoch 8/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.2336 - acc: 0.9087\n",
      "Epoch 9/20\n",
      "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2028 - acc: 0.9131\n",
      "Epoch 10/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.1936 - acc: 0.9294\n",
      "Epoch 11/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.1834 - acc: 0.9294\n",
      "Epoch 12/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.1444 - acc: 0.9444\n",
      "Epoch 13/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.1278 - acc: 0.9506\n",
      "Epoch 14/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.1013 - acc: 0.9550\n",
      "Epoch 15/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0867 - acc: 0.9663\n",
      "Epoch 16/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0607 - acc: 0.9781\n",
      "Epoch 17/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0536 - acc: 0.9831\n",
      "Epoch 18/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0257 - acc: 0.9925\n",
      "Epoch 19/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0253 - acc: 0.9931\n",
      "Epoch 20/20\n",
      "1600/1600 [==============================] - 4s 2ms/step - loss: 0.0261 - acc: 0.9894\n",
      "Computing predictions on test set...\n",
      "400/400 [==============================] - 1s 2ms/step\n",
      "Test accuracy: 85.25 %\n"
     ]
    }
   ],
   "source": [
    "tfbs_bigru = KerasClassifier(tfbs_BiGRU, epochs=40, batch_size=32, verbose=1)\n",
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_bigru)\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5398 - acc: 0.7169\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 1s 653us/step - loss: 0.3500 - acc: 0.8519\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 1s 645us/step - loss: 0.3261 - acc: 0.8663\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3030 - acc: 0.8869\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 1s 646us/step - loss: 0.2961 - acc: 0.8819\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 1s 623us/step - loss: 0.2914 - acc: 0.8831\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 1s 619us/step - loss: 0.2744 - acc: 0.8944\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 1s 605us/step - loss: 0.2675 - acc: 0.8969\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 1s 640us/step - loss: 0.2619 - acc: 0.8969\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.2494 - acc: 0.9038\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 1s 630us/step - loss: 0.2386 - acc: 0.9062\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.2341 - acc: 0.9100\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 1s 634us/step - loss: 0.2258 - acc: 0.9162\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 1s 630us/step - loss: 0.2215 - acc: 0.9131\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 1s 620us/step - loss: 0.2066 - acc: 0.9156\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 1s 643us/step - loss: 0.2037 - acc: 0.9181\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 1s 624us/step - loss: 0.1969 - acc: 0.9206\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 1s 646us/step - loss: 0.1775 - acc: 0.9281\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 1s 622us/step - loss: 0.1729 - acc: 0.9306\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 1s 638us/step - loss: 0.1515 - acc: 0.9387\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.1521 - acc: 0.9387\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.1345 - acc: 0.9481\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 1s 647us/step - loss: 0.1239 - acc: 0.9525\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.1043 - acc: 0.9612\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.0928 - acc: 0.9662\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.0721 - acc: 0.9750\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 1s 637us/step - loss: 0.0855 - acc: 0.9637\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 1s 639us/step - loss: 0.0490 - acc: 0.9869\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.0652 - acc: 0.9725\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.0834 - acc: 0.9625\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.0639 - acc: 0.9744\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 1s 637us/step - loss: 0.0326 - acc: 0.9900\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 1s 633us/step - loss: 0.0278 - acc: 0.9913\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 1s 639us/step - loss: 0.0164 - acc: 0.9931\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.0125 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.0062 - acc: 0.9975\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 1s 784us/step - loss: 0.0054 - acc: 0.9981\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.0060 - acc: 0.9969\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.0063 - acc: 0.9975\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.0052 - acc: 0.9994\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.0034 - acc: 0.9988\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.0043 - acc: 0.9981\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 9.2089e-04 - acc: 1.0000\n",
      "Computing predictions on test set...\n",
      "400/400 [==============================] - 1s 2ms/step\n",
      "Test accuracy: 87.75 %\n"
     ]
    }
   ],
   "source": [
    "tfbs_bigru = KerasClassifier(tfbs_BiGRU, epochs=50, batch_size=200, verbose=1)\n",
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, tfbs_bigru)\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Computing predictions on test set...')\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose a sample from test set\n",
    "print('Probability(positive) ='+ str(pipeline.predict_proba(X_test[0:10])))\n",
    "print('True class: ' + str(y_test[0:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seqnn]",
   "language": "python",
   "name": "conda-env-seqnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
